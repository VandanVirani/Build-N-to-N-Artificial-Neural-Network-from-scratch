## Welcome 

ğ“ğ¡ğ¢ğ¬ ğ«ğğ©ğ¨ğ¬ğ¢ğ­ğ¨ğ«ğ² ğœğ¨ğ§ğ­ğšğ¢ğ§ğ¬ ğœğ¨ğğ ğ­ğ¨ ğ›ğ®ğ¢ğ¥ğ ğ ğ­ğ¨ ğ ğšğ«ğ­ğ¢ğŸğ¢ğœğ¢ğšğ¥ ğğğ®ğ«ğšğ¥ ğğğ­ğ°ğ¨ğ«ğ¤ , ğ ğ­ğ¨ ğ ğ¦ğğšğ§ğ¬ ğ ğ§ğ®ğ¦ğ›ğğ« ğ¨ğŸ ğ¥ğšğ²ğğ«ğ¬ ğšğ§ğ ğ®ğ§ğ¢ğ­ğ¬ . 
ğ–ğ ğšğ«ğ ğ ğ¨ğ¢ğ§ğ  ğ­ğ¨ ğ®ğ¬ğ ğ­ğ¡ğ ğœğ¨ğ§ğœğğ©ğ­ ğ¨ğŸ ğ¨ğ¨ğ© ğ.ğ  ğœğ¥ğšğ¬ğ¬ , ğ¢ğ§ğ¬ğ­ğšğ§ğœğ . ğ“ğ¡ğ¢ğ¬ ğ©ğ«ğ¨ğ£ğğœğ­ ğ«ğğªğ®ğ¢ğ«ğ ğ¤ğ§ğ¨ğ°ğ¥ğğğ ğ ğšğ›ğ¨ğ®ğ­ ğ¨ğ¨ğ© ğœğ¨ğ§ğœğğ©ğ­ , ğŸğ¨ğ« ğ¥ğ¨ğ¨ğ© , ğšğ«ğ«ğšğ²ğ¬ , ğ¦ğšğ­ğ«ğ¢ğ± , ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ , ğ§ğ®ğ¦ğ©ğ² , ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ² . 
ğ–ğ ğ°ğ¢ğ¥ğ¥ ğ›ğ®ğ¢ğ¥ğ ğ¨ğ®ğ« ğ¨ğ°ğ§ ğ¦ğ¨ğğğ¥ ğšğ§ğ  ğ°ğ ğ°ğ¢ğ¥ğ¥ ğ¢ğ¦ğ©ğ¥ğğ¦ğğ§ğ­ ğŒğğˆğ’ğ“ ğğšğ­ğšğ¬ğğ­ ğ­ğ¨ ğ¨ğ®ğ« ğ¦ğ¨ğğğ¥ . 

MNIST dataset 
<img src="https://user-images.githubusercontent.com/76767487/148059145-c2b13ff0-ac67-4f79-b170-11de64a3d7a6.png" width=600 height=400 />

## ğ‹ğ„ğ“ğ’ ğ†ğ„ğ“ ğ’ğ“ğ€ğ‘ğ“ğ„ğƒ 

ğ…ğ¢ğ«ğ¬ğ­  ğ°ğ ğ°ğ¢ğ¥ğ¥ ğ®ğ¬ğ ğ­ğ¡ğ¢ğ¬ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§  ğ­ğ¨ ğ ğğ­ ğ­ğ¡ğ ğ¢ğ§ğ©ğ®ğ­ ğšğ§ğ ğ¨ğ®ğ©ğ®ğ­ ğŸğ«ğ¨ğ¦ ğ¦ğ§ğ¢ğ¬ğ­ ğğšğ­ğš . ğ“ğ¡ğ ğŒğğˆğ’ğ“ ğğšğ­ğšğ›ğšğ¬ğ (ğŒğ¨ğğ¢ğŸğ¢ğğ ğğšğ­ğ¢ğ¨ğ§ğšğ¥ ğˆğ§ğ¬ğ­ğ¢ğ­ğ®ğ­ğ ğ¨ğŸ ğ’ğ­ğšğ§ğğšğ«ğğ¬ ğšğ§ğ ğ“ğğœğ¡ğ§ğ¨ğ¥ğ¨ğ ğ² ğğšğ­ğšğ›ğšğ¬ğ[ğŸ]) ğ¢ğ¬ ğš ğ¥ğšğ«ğ ğ ğğšğ­ğšğ›ğšğ¬ğ ğ¨ğŸ ğ¡ğšğ§ğğ°ğ«ğ¢ğ­ğ­ğğ§ ğğ¢ğ ğ¢ğ­ğ¬ ğ­ğ¡ğšğ­ ğ¢ğ¬ ğœğ¨ğ¦ğ¦ğ¨ğ§ğ¥ğ² ğ®ğ¬ğğ ğŸğ¨ğ« ğ­ğ«ğšğ¢ğ§ğ¢ğ§ğ  ğ¯ğšğ«ğ¢ğ¨ğ®ğ¬ ğ¢ğ¦ğšğ ğ ğ©ğ«ğ¨ğœğğ¬ğ¬ğ¢ğ§ğ  ğ¬ğ²ğ¬ğ­ğğ¦ğ¬ . ğ“ğ¡ğ ğŒğğˆğ’ğ“ ğğšğ­ğšğ›ğšğ¬ğ ğœğ¨ğ§ğ­ğšğ¢ğ§ğ¬ ğŸ”ğŸ,ğŸğŸğŸ ğ­ğ«ğšğ¢ğ§ğ¢ğ§ğ  ğ¢ğ¦ğšğ ğğ¬ . 
ğğğœğšğ®ğ¬ğ ğ­ğ¡ğğ«ğ ğšğ«ğ ğ­ğ¨ğ­ğšğ¥ ğŸğŸ ğğ¢ğ ğ¢ğ­ğ¬ ğŸ,ğŸ,ğŸ,ğŸ‘,ğŸ’,ğŸ“,ğŸ”,ğŸ•,ğŸ–,ğŸ— ğ­ğ¡ğğ«ğ ğ°ğ¢ğ¥ğ¥ ğ›ğ ğŸğŸ ğœğ¥ğšğ¬ğ¬ ğ¢ğ§ ğ¥ğšğ¬ğ­ ğ¥ğšğ²ğğ« .
```yml 
import  numpy as np

def get_mnist():
    with np.load(f"D:/python programing/test/ann/mnist.npz") as f:
        images, labels = f["x_train"], f["y_train"]
    images = images.astype("float32") / 255
    images = np.reshape(images, (images.shape[0], images.shape[1] * images.shape[2]))
    labels = np.eye(10)[labels]
    return images, labels
input,output= get_mnist()
print(input,output)
print(input.shape,output.shape)
```
<img src="https://user-images.githubusercontent.com/76767487/148325194-287d827c-a3dd-4fda-9038-cb1349feba94.jpeg" width=900 height=600 />

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ğ°ğ ğ°ğ¢ğ¥ğ¥ ğœğ«ğğšğ­ğ ğœğ¥ğšğ¬ğ¬ ğ°ğ¡ğ¢ğœğ¡ ğ°ğ¢ğ¥ğ¥ ğ¡ğğ¥ğ© ğ­ğ¨ ğ ğğ­ ğ¢ğ§ğ¬ğ­ğšğ§ğœğ , ğšğ§ğ ğ¢ğ§ğ¬ğ¢ğğ ğ­ğ¡ğšğ­ ğŸğ¢ğ«ğ¬ğ­ ğ°ğ ğ°ğ¢ğ¥ğ¥ ğ¢ğ§ğ¢ğ­ğ¢ğšğ¥ğ¢ğ³ğ ğ¥ğ¢ğ¬ğ­ ğšğ§ğ ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ² , ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ² ğ¢ğ¬ ğ¦ğšğ¢ğ§ ğ¬ğ­ğ¨ğ«ğšğ ğ ğ­ğ¨ ğ¬ğ­ğ¨ğ«ğ ğ°ğğ¢ğ ğ¡ğ­ğ¬ , ğ®ğ§ğ¢ğ­ğ¬ .
```yml
 class ANN : 
    def __init__(self):
        self.no_of_units_in_layers=[]
        self.activation_fun=[]
        self.weights={}
        self.units={}
        self.bias={}
```
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ğğğ¥ğ¨ğ°  ,  ğ°ğ ğ¡ğšğ¯ğ ğ¦ğšğğ ğ¢ğ§ğ¬ğ­ğšğ§ğœğ ğ¨ğŸ ğ€ğğ ğœğ¥ğšğ¬ğ¬ ğ°ğ¡ğ¢ğœğ¡ ğ¢ğ¬ ğ± , ğ¡ğğ«ğ ğ°ğ ğ¡ğšğ¯ğ ğ¦ğšğğ ğš ğšğğ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğ°ğ¡ğ¢ğœğ¡ ğ°ğ¢ğ¥ğ¥ ğœğ«ğğšğ­ğ ğš ğ¥ğšğ²ğğ« , ğ¢ğ­ ğ«ğğªğ®ğ¢ğ«ğ ğ§ğ¨ ğ¨ğŸ ğ®ğ§ğ¢ğ­ğ¬ ğšğ§ğ ğšğ§ ğšğœğ­ğ¢ğ¯ğšğ­ğ¢ğ¨ğ§ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğšğ¬ğ¬ğ¨ğœğ¢ğšğ­ğğ ğ­ğ¨ ğ­ğ¡ğšğ­ ğ¥ğšğ²ğğ« . ğ°ğ ğ¡ğšğ¯ğ ğšğğğğ ğ­ğ¡ğ ğ¯ğšğ¥ğ®ğ ğ¨ğŸ ğ®ğ§ğ¢ğ­ğ¬ ğšğ§ğ ğšğœğ­ğ¢ğ¯ğšğ­ğ¢ğ¨ğ§ ğ­ğ¨ ğ¥ğ¢ğ¬ğ­ . ğ¡ğğ«ğ ğ°ğ ğ¡ğšğ¯ğ ğšğğ ğ­ğ°ğ¨ ğ­ğ¢ğ¦ğ ğšğğ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğ¦ğğšğ§ğ¬ ğ°ğ ğ¡ğšğ¯ğ ğ­ğ°ğ¨ ğ¥ğšğ²ğğ«ğ¬ ğ¨ğ§ğ ğ°ğ¢ğ­ğ¡ ğŸ‘ ğ®ğ§ğ¢ğ­ğ¬ ğ°ğ¢ğ­ğ¡ ğ¬ğ¢ğ ğ¦ğ¨ğ¢ğ ğšğœğ­ğ¢ğ¯ğšğ­ğ¢ğ¨ğ§ ğšğ§ğ ğ¬ğğœğ¨ğ§ğ ğ¢ğ¬ ğŸ ğ®ğ§ğ¢ğ­ğ¬ . ğ¥ğšğ¬ğ­ ğ­ğ¢ğ¦ğ ğ°ğ ğœğšğ¥ğ¥ ğšğğ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğ¢ğ¬ ğ¨ğ®ğ« ğ¨ğ®ğ­ğ©ğ®ğ­ ğ¥ğšğ²ğğ« , ğ°ğ ğ¡ğšğ¯ğ ğŸ ğ®ğ§ğ¢ğ­ğ¬ ğ¢ğ§ ğ¨ğ®ğ­ğ©ğ®ğ­ ğ¥ğšğ²ğğ« ğ¦ğğšğ§ğ¬ ğ°ğ ğ¡ğšğ¯ğ ğŸ ğœğ¥ğšğ¬ğ¬ (:. ğ¥ğ¢ğ¤ğ ğœğšğ­,ğğ¨ğ  ).
```yml
class ANN:
    def __init__(self):
        self.no_of_units_in_layers=[]
        self.activation_fun=[]
        self.weights={}
        self.units={}
        self.bias={}
    
    def add(self,unit,activation=0):                 # default value of activation is 0
        self.no_of_units_in_layers.append(int(unit))   # append the information in no_of_units_in_layers list
        self.activation_fun.append(activation)         # append the information in activation_fun list

x=ANN()
x.add(3,"sigmoid")
x.add(10)   # because 10 class are there 
```        
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ğğ¨ğ° ğ¢ğ­ğ¬ ğ­ğ¢ğ¦ğ ğ­ğ¨ ğœğ«ğğšğ­ğ ğšğœğ­ğ¢ğ¯ğšğ­ğ¢ğ¨ğ§ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ , ğ¢ğ­ ğ­ğšğ¤ğğ¬ ğ­ğ°ğ¨ ğšğ«ğ ğ®ğ¦ğğ§ğ­ğ¬ ğŸğ¢ğ«ğ¬ğ­ ğ¢ğ¬ ğšğ«ğ«ğšğ² ğšğ§ğ ğ¬ğğœğ¨ğ§ğ ğ¢ğ¬ ğš ğ§ğ®ğ¦ğ›ğğ« ğ¢ğ­ ğ­ğğ¥ğ¥ğ¬ ğ°ğ¡ğšğ­ ğ¥ğšğ²ğğ« ğ§ğğğ ğ­ğ¨ ğ®ğ¬ğ ğ°ğ¡ğ¢ğœğ¡ ğšğœğ­ğ¢ğ¯ğšğ­ğ¢ğ¨ğ§ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ . 
ğ¬ğ¢ğ ğ¦ğ¨ğ¢ğ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ : ğœğ¨ğ§ğ¯ğğ«ğ­ğ¬ +ğ¢ğ¯ğ ğ¢ğ§ğ­ğğ ğğ« ğ­ğ¨ ğš  ğ§ğ®ğ¦ğ›ğğ« ğ¢ğ§ ğ›ğğ­ğ°ğğğ§ ğŸ ğ­ğ¨ ğŸ . ğŸğ¨ğ«ğ¦ğ®ğ¥ğš ğ¢ğ¬ ğŸ / (ğŸ + ğ**(-ğ±) ) , ğ°ğ ğ¡ğšğ¯ğ ğ®ğ¬ğ ğ¦ğšğ­ğ¡ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğ­ğ¨ ğ®ğ¬ğ ğ¯ğšğ¥ğ®ğ ğ¨ğŸ ğ . 
ğ«ğğ¥ğ® ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§    : ğ¢ğŸ ğ¯ğšğ¥ğ®ğ ğ¥ğğ¬ğ¬ ğ­ğ¡ğšğ§ ğŸ ğ­ğ¡ğšğ§ ğ¢ğ­ ğ°ğ¢ğ¥ğ¥ ğ«ğğ­ğ®ğ«ğ§ ğŸ ğ¨ğ­ğ¡ğğ«ğ°ğ¢ğ¬ğ ğ¢ğ­ ğ°ğ¢ğ¥ğ¥ ğ«ğğ­ğ®ğ«ğ§ ğ­ğ¡ğ ğ¨ğ«ğ¢ğ ğ¢ğ§ğšğ¥ ğ¯ğšğ¥ğ®ğ .
```yml
class ANN:
    import math
    def __init__(self):
        self.no_of_units_in_layers=[]
        self.activation_fun=[]
        self.weights={}
        self.units={}
        self.bias={}
    
    def add(self,unit=0,activation=0):  # default value of activation is 0
        self.no_of_units_in_layers.append(int(unit))
        self.activation_fun.append(activation)
    def activation_function(self,x,i):
        if self.activation_fun[i]=="sigmoid":
            return 1/(1 + self.math.e**(-x))
        elif self.activation_fun[i]=="relu":
            return x*(x>0)    
x=ANN()
x.add(3,"sigmoid")
x.add(2)
```     
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ğğ¨ğ° ğ¢ğ­ğ¬ ğ­ğ¢ğ¦ğ ğ­ğ¨ ğ­ğšğ¤ğ ğ¢ğ§ğ©ğ®ğ­ , ğ¨ğ®ğ­ğ©ğ®ğ­ , ğ¥ğğšğ«ğ§ğ¢ğ§ğ  ğ«ğšğ­ğ , ğğ©ğ¨ğœğ¡ğ¬ ğ­ğ¨ ğ¨ğ®ğ« ğ¦ğ¨ğğğ¥ .ğ­ğ¨ ğğ¨ ğ­ğ¡ğšğ­ ğ°ğ ğ¡ğšğ¯ğ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğœğšğ¥ğ¥ğğ ğšğ§ğ§. ğšğ¥ğ¥ ğ­ğ¡ğ ğ­ğ¡ğ¢ğ§ğ ğ¬ ğ¡ğšğ©ğ©ğğ§ ğ¢ğ§ğ¬ğ¢ğğ ğ­ğ¡ğ ğšğ§ğ§ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ . ğ°ğ ğ®ğ¬ğ ğ§ğ®ğ¦ğ©ğ² ğ¥ğ¢ğ›ğ«ğšğ«ğ² ğŸğ¨ğ« ğœğ«ğğšğ­ğ¢ğ¨ğ§ ğ¨ğŸ ğšğ«ğ«ğšğ² , ğ ğğ­ğ­ğ¢ğ§ğ  ğ«ğšğ§ğğ¨ğ¦ ğ¯ğšğ¥ğ®ğğ¬ . ğ–ğ ğ¡ğšğ¯ğ ğœğšğ¥ğ¥ ğšğ§ğ§ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğšğ­ ğ¥ğšğ¬ğ­ ğ¢ğ§ ğœğ¨ğğ. ğ¢ğ§ğ©ğ®ğ­ ğ¢ğ¬ ğšğ§ ğšğ«ğ«ğšğ² ğŸğ¨ğ« ğğ±ğšğ©ğ¥ğ ğŒğğˆğ’ğ“ ğğšğ­ğšğ¬ğğ­ ğœğ¨ğ§ğ­ğšğ¢ğ§ğ¬ 
ğŸ) ğœğ«ğğšğ­ğ¢ğ¨ğ§ ğ¨ğŸ ğ°ğğ¢ğ ğ¡ğ­ğ¬ : ğ¢ğ§ğ¢ğ­ğ¢ğšğ¥ğ¥ğ² ğ­ğ¡ğ ğ¯ğšğ¥ğ®ğ ğ¨ğŸ ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğ¢ğ¬ ğ«ğšğ§ğğ¨ğ¦ ğšğ§ğ ğ ğğ­ ğœğ¡ğšğ§ğ ğ ğ›ğ² ğ›ğšğœğ¤ğ©ğ«ğ¨ğ©ğšğ ğšğ­ğ¢ğ¨ğ§ . ğ­ğ¨ ğ¬ğ­ğ¨ğ«ğ ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğ°ğ ğ®ğ¬ğ ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ²

```yml

class ANN:
    import math,numpy as np
    def __init__(self):
        self.no_of_units_in_layers=[]
        self.activation_fun=[]
        self.weights={}
        self.units={}
        self.bias={}
    
    def add(self,unit=0,activation=0):  # default value of activation is 0
        self.no_of_units_in_layers.append(int(unit))
        self.activation_fun.append(activation)
    def activation_function(self,x,i):
        if self.activation_fun[i]=="sigmoid":
            return 1/(1 + self.math.e**(-x))
        elif self.activation_fun[i]=="relu":
            return x*(x>0)    
    def ann(self,inputs,outputs,epochs=10,learning_rate=0.1):  # default value  of learning rate is 0.1 and epochs is 10 
       ###### creation of weights 
       self.weights['0']=np.random.uniform(-0.5,0.5,(len(inputs[0]),self.no_of_units_in_layers[0]))
       for i in range(len(self.no_of_units_in_layers)-1):
           self.weights['{}'.format(i+1)]=np.random.uniform(-0.5,0.5,(self.no_of_units_in_layers[i],self.no_of_units_in_layers[i+1]))
       print("weights : ",self.weights)    
       ###### initializing the units 
       for i in range(len(self.no_of_units_in_layers)):
           self.units['{}'.format(i+1)] = np.zeros(self.no_of_units_in_layers[i])
       print("units : ",self.units)        
       for i in range(len(self.units)):
           self.bias['{}'.format(i+1)]=np.zeros(len(self.units['{}'.format(i+1)]))
       print("bias : ",self.bias)    
       
x=ANN()
x.add(3,"sigmoid")
x.add(10)
x.ann(input,output,5,learning_rate=0.01)    # input and output are taken from mnist dataset . 
```  

<img src="https://user-images.githubusercontent.com/76767487/148326714-1543568b-bd7d-4b36-8e71-06b12e3107c9.jpg" width=900 height=230 />

ğğ¨ğ° ğ°ğ ğ°ğ¢ğ¥ğ¥ ğ›ğ ğ­ğ¡ğ¢ğ§ğ¤ğ¢ğ§ğ  ğ¡ğ¨ğ° ğ¢ ğ¡ğšğ¯ğ ğœğ«ğğšğ­ğğ ğ°ğğ¢ğ ğ¡ğ­ğ¬ . ğ¬ğğ ğ›ğğ¥ğ¨ğ° ğ¢ğ¦ğšğ ğ



![WhatsApp Image 2022-01-06 at 9 59 03 AM](https://user-images.githubusercontent.com/76767487/148328318-cb6342a4-db48-4b8a-9962-e4ba904fb66e.jpeg)

ğˆğ§ğ¢ğ­ğ¢ğšğ¥ğ¥ğ² ğ­ğ¡ğ ğ®ğ§ğ¢ğ­ğ¬ ğ¯ğšğ¥ğ®ğ ğ¢ğ§ ğ®ğ§ğ¢ğ­ğ¬ ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ² ğ¢ğ¬ ğŸ , ğ¢ğ­ ğ°ğ¢ğ¥ğ¥ ğœğ¡ğšğ§ğ ğğ ğğ®ğ«ğ¢ğ§ğ  ğŸğ¨ğ«ğ°ğšğ«ğ ğ©ğ«ğ¨ğ©ğšğ ğšğ­ğ¢ğ¨ğ§ .

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 

## FORWARD PROPAGATION  


```yml
def ann(self,inputs,outputs,epochs=10,learning_rate=0.1):  # default value  of learning rate is 0.1 and epochs is 10 
       ###### creation of weights 
       self.weights['0']=np.random.uniform(-0.5,0.5,(len(inputs[0]),self.no_of_units_in_layers[0]))
       for i in range(len(self.no_of_units_in_layers)-1):
           self.weights['{}'.format(i+1)]=np.random.uniform(-0.5,0.5,(self.no_of_units_in_layers[i],self.no_of_units_in_layers[i+1]))
       print("weights : ",self.weights)    
       ###### initializing the units 
       for i in range(len(self.no_of_units_in_layers)):
           self.units['{}'.format(i+1)] = np.zeros(self.no_of_units_in_layers[i])
       print("units : ",self.units)        
       for i in range(len(self.units)):
           self.bias['{}'.format(i+1)]=np.zeros(len(self.units['{}'.format(i+1)]))
       print("bias : ",self.bias)    
       
       #-------------------------------------------------------->
       for y in range(epochs):
         for e in range(len(outputs)):
            self.units['0']=input[e]
            self.units['real']=outputs[e]
            
            ######   forward phase 
            ########## change one  dimentional array in unit_dict in to two dimensional
            self.units['{}'.format(0)]=np.reshape(self.units['{}'.format(0)],(1,-1))   # because we want to calculate matrix multiplication 
            def forward(units,weights,bias):
                for i in range(len(units)-2):
                    units['{}'.format(i+1)] = self.np.reshape(self.sigmoid(self.np.dot(units['{}'.format(i)] ,weights['{}'.format(i)] )+bias['{}'.format(i+1)],i) ,(-1,))        
            forward(self.units,self.weights,self.bias)
            ########## change two dimentional array in unit_dict in to one dimensional
            self.units['{}'.format(0)]= self.np.reshape(self.units['{}'.format(0)],(-1,))
```  

ğ¡ğğ«ğ , ğ­ğ¡ğ ğœğ«ğğšğ­ğ¢ğ¨ğ§ ğ¨ğŸ ğ°ğğ¢ğ ğ¡ğ­ğ¬ , ğ›ğ¢ğšğ¬ , ğ¢ğ§ğ¢ğ­ğ¢ğšğ¥ğ¢ğ³ğ¢ğ§ğ  ğ®ğ§ğ¢ğ­ğ¬ ğ°ğ¢ğ¥ğ¥ ğ«ğ®ğ§ ğ¨ğ§ğ¥ğ² ğ¨ğ§ğ ğ­ğ¢ğ¦ğ ğ›ğ®ğ­ ğ­ğ¡ğ ğŸğ¨ğ«ğ°ğšğ«ğ ğ©ğ«ğ¨ğ©ğšğ ğšğ­ğ¢ğ¨ğ§ , ğ›ğšğœğ¤ğ°ğšğœğ¤ğ©ğ«ğšğ©ğšğ ğšğ­ğ¢ğ¨ğ§ ğ°ğ¢ğ¥ğ¥ ğ«ğ®ğ§ ğ¦ğ¨ğ«ğ ğ­ğ¡ğšğ§ ğ¨ğ§ğ ğŸğ¨ğ« ğ­ğ«ğšğ¢ğ§ğ¢ğ§ğ  ğ¬ğ¨ ğ°ğ ğ°ğ¢ğ¥ ğ°ğ«ğ¢ğ­ğ ğğ§ğ­ğ¢ğ«ğ ğŸğ¨ğ«ğ°ğšğ«ğ ğšğ§ğ ğ›ğšğœğ¤ğ°ğšğ«ğ ğœğ¨ğğ ğ¢ğ§ ğŸğ¨ğ« ğ¥ğ¨ğ¨ğ© , ğ“ğ¡ğ ğ«ğğ ğ®ğ¥ğšğ«ğ¢ğ¬ğšğ­ğ¢ğ¨ğ§ ğ¨ğŸ ğ­ğ¡ğ ğŸğ¨ğ« ğ¥ğ¨ğ¨ğ© ğ°ğ¢ğ¥ğ¥ ğ›ğ ğğ¨ğ§ğ ğ›ğ² ğğ©ğ¨ğœğ¡ğ¬ , ğ¢ğŸ ğğ©ğ¨ğœğ¡ğ¬ ğ¢ğ¬ ğŸ ğ­ğ¡ğ ğ¨ğ®ğ« ğœğ¨ğğ ğ°ğ¢ğ¥ğ¥ ğšğ§ğšğ¥ğ²ğ¬ğ ğ­ğ¡ğ ğğ§ğ­ğ¢ğ«ğ ğğšğ­ğšğ¬ğğ­ ğ¨ğ§ğœğ , ğ¢ğŸ ğğ©ğ¨ğœğ¡ğ¬ ğ¢ğ¬ ğŸğŸ ğ­ğ¡ğğ§ ğ¢ğ­ ğ°ğ¢ğ¥ğ¥ ğ¬ğœğšğ§ ğŸğŸ ğ­ğ¢ğ¦ğğ¬ . ğ¢ğŸ ğ²ğ¨ğ® ğğ¨ğ§'ğ­ ğ®ğ§ğğğ«ğ¬ğ­ğšğ§ğ ğ­ğ¡ğğ§ ğ­ğ«ğ² ğ­ğ¨ ğ«ğ®ğ§ ğ­ğ¡ğ ğ©ğšğ«ğ­ğ¬ ğ¨ğŸ ğ­ğ¡ğ ğœğ¨ğğ .


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 
##ğ‹ğğ’ğ’ 

ğ°ğ ğšğ«ğ ğšğğğ¢ğ§ğ  ğ¥ğ¨ğ¬ğ¬ ğœğšğ¥ğœğ®ğ¥ğšğ­ğ¢ğ¨ğ§ , ğ¥ğ¨ğ¬ğ¬ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğœğšğ§ ğ›ğ ğ¯ğšğ«ğ¢ğğ¬ , ğ¡ğğ«ğ ğ°ğ ğ®ğ¬ğğ ğ¬ğªğ®ğšğ«ğğ ğ¥ğ¨ğ¬ğ¬ ğ¢ğ§ ğšğ§ğ§ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğšğŸğ­ğğ« ğŸğ¨ğ«ğ°ğšğ«ğ ğ©ğ«ğ¨ğ©ğšğ ğšğ­ğ¢ğ¨ğ§ .

```         
            error = (1/len(self.units['real']))* np.sum ((self.units['{}'.format(len(self.units)-2)] - self.units['real'] )**2)
            ######## to check how many data classied correctly in training after how many epochs
            print("    error is  =>  ",error , "   and epochs is   ", y,"  ",e)
```            

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 
## ğğ€ğ‚ğŠğğ‘ğğğ€ğ†ğ€ğ“ğˆğğ 

ğ§ğ¨ğ° ğ°ğ ğšğ«ğ ğ®ğ¬ğ¢ğ§ğ  ğš ğ§ğğ° ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ² ğ°ğ¡ğ¢ğœğ¡ ğ¢ğ¬ ğš ğœğ¨ğ©ğ² ğ¨ğŸ ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğ°ğ¡ğ¢ğœğ¡ ğ°ğ¢ğ¥ğ¥ ğ¬ğ­ğ¨ğ«ğ ğ©ğšğ«ğ­ğ¢ğšğ¥ ğğğ«ğ¢ğ¯ğšğ­ğ¢ğğ¬ , ğ²ğ¨ğ® ğ°ğ¢ğ¥ğ¥  ğ­ğ¡ğ¢ğ§ğ¤ " ğ°ğ¡ğšğ­ ğˆ ğ¡ğšğ¯ğ ğğ¨ğ§ğ " . ğ­ğ¡ğšğ­ ğ°ğ¡ğ² ğ¢ğ­ ğ¢ğ¬ ğ§ğğœğœğğ¬ğ¬ğšğ«ğ² ğ­ğ¨ ğ®ğ§ğğğ«ğ¬ğ­ğšğ§ğ ğ­ğ¡ğ ğ¦ğšğ­ğ¡ğğ¦ğšğ­ğ¢ğœğ¬ ğ›ğğ¡ğ¢ğ§ğ ğ­ğ¡ğ ğ›ğšğœğ¤ğ©ğ«ğ¨ğ©ğšğ ğšğ­ğ¢ğ¨ğ§
```yml
   def ann(self,inputs,outputs,epochs,learning_rate=0.1):
       ###### creation of weights 
       self.weights['0']=np.random.uniform(-0.5,0.5,(len(inputs[0]),self.no_of_units_in_layers[0]))
       for i in range(len(self.no_of_units_in_layers)-1):
           self.weights['{}'.format(i+1)]=np.random.uniform(-0.5,0.5,(self.no_of_units_in_layers[i],self.no_of_units_in_layers[i+1]))
       for i in range(len(self.no_of_units_in_layers)):
           self.units['{}'.format(i+1)] = np.zeros(self.no_of_units_in_layers[i])
       for i in range(len(self.units)):
           self.bias['{}'.format(i+1)]=np.zeros(len(self.units['{}'.format(i+1)]))
       for y in range(epochs):
         for e in range(len(outputs)):
            self.units['0']=input[e]
            self.units['real']=outputs[e]
            ######   forward phase 
            self.units['{}'.format(0)]=np.reshape(self.units['{}'.format(0)],(1,-1))
            def forward(units,weights,bias):
                for i in range(len(units)-2):
                    units['{}'.format(i+1)] = self.np.reshape(self.sigmoid(self.np.dot(units['{}'.format(i)] ,weights['{}'.format(i)] )+bias['{}'.format(i+1)],i) ,(-1,))        
            forward(self.units,self.weights,self.bias)
            ########## change two dimentional array in unit_dict in to one dimensional
            self.units['{}'.format(0)]= self.np.reshape(self.units['{}'.format(0)],(-1,))
            
            
            ##############  error cost function
            error=(1/len(self.units['real']))* np.sum ((self.units['{}'.format(len(self.units)-2)] - self.units['real'] )**2)
            ######## to check how many data classied correctly in training after how many epochs
            print("    error is  =>  ",error , "   and epochs is   ", y,"  ",e)
            
            
            
            ######## back propagation phase 
            pd_backward_weights=self.copy.deepcopy(self.weights)
            def activ_diff(y):  # we used this function  because of user choise whether the function is sigmoid or relu
                if self.activation_fun[y]=="sigmoid":
                    return self.units['{}'.format(y+1)]*(1-self.units['{}'.format(y+1)])
                elif self.activation_fun[y]=="relu":
                    return self.units['{}'.format(y+1)]*(self.units['{}'.format(y+1)]>0)
                elif self.activation_fun[y]==0:
                    return y       
            def backward(pd_backward_weights):
                #------------------------------------->
                # this is for last layer
                dd = (self.units["{}".format(len(self.units)-2)] - self.units["real"]) * activ_diff(len(self.units)-3) 
                self.bias['{}'.format(len(self.units)-2)] += - learning_rate* dd
                pd_backward_weights['{}'.format(len(self.units)-3)] = dd *self.units['{}'.format(len(self.units)-3)].reshape(-1,1)
                dd = dd* self.weights['{}'.format(len(self.units)-3)]
                self.weights['{}'.format(len(self.units)-3)] += - learning_rate* pd_backward_weights['{}'.format(len(self.units)-3)]
 
                #------------------------------------->
                # this is for all layer except last 
                for i in reversed(range(len(self.weights)-1)):
                   dd = np.sum(dd * activ_diff(i).reshape(-1,1),axis=1)
                   self.bias['{}'.format(i+1)] += - learning_rate*dd
                   pd_backward_weights['{}'.format(i)] = dd * self.units['{}'.format(i)].reshape(-1,1)
                   dd = dd * self.weights['{}'.format(i)]
                   self.weights['{}'.format(i)] += - learning_rate* pd_backward_weights['{}'.format(i)]
            backward(pd_backward_weights)
```

ğˆğ§ ğ›ğšğœğ¤ğ©ğ«ğ¨ğ©ğšğ ğšğ­ğ¢ğ¨ğ§ ğ°ğ ğ¡ğšğ¯ğ ğ­ğ¨ ğ®ğ©ğšğğšğ­ğ ğ›ğ¨ğ­ğ¡ ğ­ğ¡ğ ğ›ğ¢ğšğ¬ ğšğ§ğ ğ°ğğ¢ğ ğ¡ğ­ , ğ­ğ¡ğğ¢ğ« ğ­ğ¡ğğ«ğ ğšğ«ğ ğ­ğ°ğ¨ ğğ¢ğœğ­ ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğšğ§ğ ğ©ğ_ğ›ğšğœğ¤ğ°ğšğ«ğ_ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğ°ğ¡ğ¢ğœğ¡ ğ¢ğ¬ ğš ğœğ¨ğ©ğ² ğ¨ğŸ ğ°ğğ¢ğ ğ¡ğ­ğ¬ , ğ§ğ¨ğ° ğ°ğ ğ°ğ¢ğ¥ğ¥ ğ¬ğ­ğ¨ğ«ğ ğšğ¥ğ¥ ğ­ğ¡ğ ğ©ğšğ«ğ­ğ¢ğšğ¥ ğğğ«ğ¢ğ¯ğšğ­ğ¢ğ¯ğğ¬ ğ¢ğ§ ğ©ğ_ğ›ğšğ¤ğœğ°ğšğ«ğ_ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğ›ğğœğšğ®ğ¬ğ ğ°ğ ğ°ğšğ§ğ­ ğ­ğ¨ ğ¬ğ­ğ¨ğ«ğ ğ§ğğ° ğ¯ğšğ¥ğ®ğ ğ¨ğŸ ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğ¢ğ§ ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ² ğ¬ğ¨ ğ°ğ ğ°ğ¢ğ¥ğ¥ ğ¬ğ¢ğ¦ğ©ğ¥ğ² ğğ¨ ğœğšğ¥ğ®ğœğšğ­ğ¢ğ¨ğ§ ğ¨ğŸ ğŸğ¨ğ«ğ¦ğ®ğ¥ğš ( ğ¨ğ¥ğ_ğ° - ğ‹ğ‘ * ğğ¢ğŸğŸ) ğ¨ğ§ ğ©ğ_ğ›ğšğ¤ğœğ°ğšğ«ğ_ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğšğ§ğ ğ¬ğ­ğ¨ğ«ğ ğ­ğ¡ğ ğ¨ğ®ğ­ğ©ğ®ğ­ (ğ§ğğ° ğ¯ğšğ¥ğ®ğ ) ğ¢ğ§ ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ² ğ¬ğ¨ ğ¢ğ§ ğ§ğğ±ğ­ ğ¥ğ¨ğ¨ğ© ğ®ğ©ğğšğ­ğğ ğ°ğğ¢ğ ğ¡ğ­ğ¬ ğğ¢ğœğ­ğ¢ğ¨ğ§ğšğ«ğ² ğ°ğ¢ğ¥ğ¥ ğ›ğ ğ®ğ¬ğğ . ğ“ğ¡ğğ§ ğ¬ğšğ¦ğ ğ©ğ«ğ¨ğœğğ¬ğ¬ ğ°ğ¢ğ¥ğ¥ ğ«ğ®ğ§ ğŸğ¨ğ«ğ°ğšğ«ğ ğšğ§ğ ğ›ğšğœğ¤ğ°ğšğ«ğ .


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 
## ğğ‘ğ„ğƒğˆğ‚ğ“ğˆğğ 

ğ§ğ¨ğ° ğ°ğ  ğ°ğ¢ğ¥ğ¥ ğšğğ ğ©ğ«ğğğ¢ğœğ­ğ¢ğ¨ğ§ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğ¨ğ®ğ­ğ¬ğ¢ğğ ğ­ğ¡ğ ğšğ§ğ§ ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§  
```yml
def prediction(self,x):
        self.units['0']=x
        for i in range(len(self.units)-1):
            self.units['{}'.format(i)]= np.reshape(self.units['{}'.format(i)],(1,-1)) 
        def forward(units,weights,bias):
            for i in range(len(units)-2):
                units['{}'.format(i+1)] = self.sigmoid(np.dot(units['{}'.format(i)] ,weights['{}'.format(i)] )+bias['{}'.format(i+1)],i)
        forward(self.units,self.weights,self.bias)
        for i in range(len(self.units)-1):
            self.units['{}'.format(i)]= np.reshape(self.units['{}'.format(i)],(-1))     
        return(np.argmax(self.units['{}'.format(len(self.units)-2)]))
```
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# LETS SUM IT ALL 

```yml
import  numpy as np

def get_mnist():
    with np.load(f"C:\\Users\\Ravi\\Desktop\\train\\mnist.npz") as f:
        images, labels = f["x_train"], f["y_train"]
    images = images.astype("float32") / 255
    images = np.reshape(images, (images.shape[0], images.shape[1] * images.shape[2]))
    labels = np.eye(10)[labels]
    return images, labels
input,output= get_mnist()

class ANN:
    import numpy as np,math,copy
    np.random.seed(42)
    def __init__(self):
        self.no_of_units_in_layers=[]
        self.activation_fun=[]
        self.weights={}
        self.units={}
        self.bias={}
    def add(self,unit=0,activation=0):
        self.no_of_units_in_layers.append(int(unit))
        self.activation_fun.append(activation)
    def sigmoid(self,x,i):
        if self.activation_fun[i]=="sigmoid":
            return 1/(1 + self.math.e**(-x))
        elif self.activation_fun[i]=="relu":
            if x<0:
                return 0
            else:
                return x
        elif self.activation_fun[i]=="softplus":
           return self.math.log(1+self.math.e**x,base=self.math.e)
        elif self.activation_fun[i]=="tanh":
            return (self.math.e**x - self.math.e**(-x))/(self.math.e**x + self.math.e**(-x))
        else :
            return x    
    def ann(self,inputs,outputs,epochs,learning_rate=0.1):
       ###### creation of weights 
       self.weights['0']=np.random.uniform(-0.5,0.5,(len(inputs[0]),self.no_of_units_in_layers[0]))
       for i in range(len(self.no_of_units_in_layers)-1):
           self.weights['{}'.format(i+1)]=np.random.uniform(-0.5,0.5,(self.no_of_units_in_layers[i],self.no_of_units_in_layers[i+1]))
       for i in range(len(self.no_of_units_in_layers)):
           self.units['{}'.format(i+1)] = np.zeros(self.no_of_units_in_layers[i])
       for i in range(len(self.units)):
           self.bias['{}'.format(i+1)]=np.zeros(len(self.units['{}'.format(i+1)]))
       for y in range(epochs):
         for e in range(len(outputs)):
            self.units['0']=input[e]
            self.units['real']=outputs[e]
            ######   forward phase 
            self.units['{}'.format(0)]=np.reshape(self.units['{}'.format(0)],(1,-1))
            def forward(units,weights,bias):
                for i in range(len(units)-2):
                    units['{}'.format(i+1)] = self.np.reshape(self.sigmoid(self.np.dot(units['{}'.format(i)] ,weights['{}'.format(i)] )+bias['{}'.format(i+1)],i) ,(-1,))        
            forward(self.units,self.weights,self.bias)
            ########## change two dimentional array in unit_dict in to one dimensional
            self.units['{}'.format(0)]= self.np.reshape(self.units['{}'.format(0)],(-1,))
            ##############  error cost function
            error=(1/len(self.units['real']))* np.sum ((self.units['{}'.format(len(self.units)-2)] - self.units['real'] )**2)
            ######## to check how many data classied correctly in training after how many epochs
            print("    error is  =>  ",error , "   and epochs is   ", y,"  ",e)
            ######## back propagation phase 
            pd_backward_weights=self.copy.deepcopy(self.weights)
            def activ_diff(y):
                if self.activation_fun[y]=="sigmoid":
                    return self.units['{}'.format(y+1)]*(1-self.units['{}'.format(y+1)])
                elif self.activation_fun[y]=="relu":
                    return self.units['{}'.format(y+1)]*(self.units['{}'.format(y+1)]>0)    
                elif self.activation_fun[y]==0:
                    return y       
            def backward(pd_backward_weights):
                dd = (self.units["{}".format(len(self.units)-2)] - self.units["real"]) * activ_diff(len(self.units)-3) 
                self.bias['{}'.format(len(self.units)-2)] += - learning_rate* dd
                pd_backward_weights['{}'.format(len(self.units)-3)] = dd *self.units['{}'.format(len(self.units)-3)].reshape(-1,1)
                dd = dd* self.weights['{}'.format(len(self.units)-3)]
                self.weights['{}'.format(len(self.units)-3)] += - learning_rate* pd_backward_weights['{}'.format(len(self.units)-3)]

                for i in reversed(range(len(self.weights)-1)):
                   dd = np.sum(dd * activ_diff(i).reshape(-1,1),axis=1)
                   self.bias['{}'.format(i+1)] += - learning_rate*dd
                   pd_backward_weights['{}'.format(i)] = dd * self.units['{}'.format(i)].reshape(-1,1)
                   dd = dd * self.weights['{}'.format(i)]
                   self.weights['{}'.format(i)] += - learning_rate* pd_backward_weights['{}'.format(i)]
            backward(pd_backward_weights)
    def prediction(self,x):
        self.units['0']=x
        for i in range(len(self.units)-1):
            self.units['{}'.format(i)]= np.reshape(self.units['{}'.format(i)],(1,-1)) 
        def forward(units,weights,bias):
            for i in range(len(units)-2):
                units['{}'.format(i+1)] = self.sigmoid(np.dot(units['{}'.format(i)] ,weights['{}'.format(i)] )+bias['{}'.format(i+1)],i)
        forward(self.units,self.weights,self.bias)
        for i in range(len(self.units)-1):
            self.units['{}'.format(i)]= np.reshape(self.units['{}'.format(i)],(-1))     
        return(np.argmax(self.units['{}'.format(len(self.units)-2)]))

x=ANN()
x.add(15,"sigmoid")
x.add(10)
x.ann(input,output,5,learning_rate=0.01)    # input and output are taken from mnist dataset .
correct_counter=0
for i in range(5999):
    if x.prediction(input[i+54000]) ==np.argmax(output[i+54000]):
      correct_counter+=1
print("percentage is ",(correct_counter/5999)*100," %")
```

